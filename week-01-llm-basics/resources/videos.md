# Week 1 Video Resources

## üé¨ Essential Watching

### Transformer Architecture
1. **The Illustrated Transformer by Jay Alammar**
   - Duration: 15 minutes
   - Link: [YouTube](https://www.youtube.com/watch?v=4Bdc55j80l8)
   - Key Topics: Attention mechanism, encoder-decoder structure

2. **Attention is All You Need - Paper Explained**
   - Duration: 20 minutes
   - Link: [YouTube](https://www.youtube.com/watch?v=iDulhoQ2pro)
   - Key Topics: Original paper walkthrough

### LLM Fundamentals
3. **What are Large Language Models (LLMs)?**
   - Duration: 12 minutes
   - Link: [YouTube](https://www.youtube.com/watch?v=5sLYAQS9sWQ)
   - Key Topics: GPT, BERT, T5 comparison

4. **How ChatGPT Works**
   - Duration: 18 minutes
   - Link: [YouTube](https://www.youtube.com/watch?v=e0aKI2GGZNg)
   - Key Topics: Training process, RLHF

### Tokenization Deep Dive
5. **Understanding Tokenization in NLP**
   - Duration: 10 minutes
   - Link: [YouTube](https://www.youtube.com/watch?v=zduSFxRajkE)
   - Key Topics: BPE, WordPiece, SentencePiece

## üîß Practical Tutorials

### API Usage
6. **OpenAI API Tutorial for Beginners**
   - Duration: 25 minutes
   - Link: [YouTube](https://www.youtube.com/watch?v=c-g6epk3fFE)
   - Key Topics: Setup, first API call, parameters

7. **Hugging Face Transformers Tutorial**
   - Duration: 30 minutes
   - Link: [YouTube](https://www.youtube.com/watch?v=QEaBAZQCtwE)
   - Key Topics: Loading models, tokenization, inference

### Environment Setup
8. **Python Environment for ML/AI**
   - Duration: 15 minutes
   - Link: [YouTube](https://www.youtube.com/watch?v=PUPO7ce6b4o)
   - Key Topics: Virtual environments, package management

## üìö Course Series

### DeepLearning.AI Courses
9. **How Transformer LLMs Work**
   - Duration: 2 hours (complete course)
   - Link: [DeepLearning.AI](https://www.deeplearning.ai/short-courses/how-transformer-llms-work/)
   - Key Topics: Comprehensive transformer understanding

### Andrej Karpathy's Series
10. **Let's Build GPT**
    - Duration: 2 hours
    - Link: [YouTube](https://www.youtube.com/watch?v=kCc8FmEb1nY)
    - Key Topics: Building transformer from scratch

## üéØ This Week's Focus

**Must Watch Before Day 3:**
- Videos 1, 3, 5, 6

**Recommended for Deep Understanding:**
- Videos 2, 4, 7, 9

**Advanced (Optional):**
- Videos 8, 10

## üí° Viewing Tips

1. **Take Notes**: Keep a notebook for key concepts
2. **Pause and Code**: Try examples shown in tutorials
3. **Discuss**: Share insights in our Discord channel
4. **Question Everything**: Come to office hours with questions

## üèÜ Video Discussion Points

After watching, consider these questions:
1. How does self-attention differ from traditional attention?
2. Why do we need positional encoding in transformers?
3. What are the trade-offs between different tokenization methods?
4. How do API parameters affect model outputs?
