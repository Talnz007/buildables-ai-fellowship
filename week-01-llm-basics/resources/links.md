# Week 1 Resources & Links

## ğŸ“– Official Documentation
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index)
- [Python OpenAI Library](https://github.com/openai/openai-python)

## ğŸ“ Educational Resources
- [How Transformer LLMs Work - DeepLearning.AI](https://www.deeplearning.ai/short-courses/how-transformer-llms-work/)
- [The Illustrated Transformer - Jay Alammar](https://jalammar.github.io/illustrated-transformer/)
- [LLM Architecture Overview - Medium](https://medium.com/@b.terryjack/llm-architecture-the-backbone-of-modern-ai-systems-ae7369fed19e)

## ğŸ”§ Development Tools
- [OpenAI Playground](https://platform.openai.com/playground)
- [Hugging Face Model Hub](https://huggingface.co/models)
- [Tokenizer Playground](https://platform.openai.com/tokenizer)

## ğŸ“Š Datasets for Practice
- [Common Crawl](https://commoncrawl.org/)
- [OpenWebText](https://github.com/jcpeterson/openwebtext)
- [WikiText](https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/)

## ğŸ¢ Industry Applications
- [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774)
- [LLaMA Paper](https://arxiv.org/abs/2302.13971)
- [Claude Architecture](https://www.anthropic.com/research)

## ğŸ¯ Practice Platforms
- [Kaggle Learn AI Courses](https://www.kaggle.com/learn/intro-to-machine-learning)
- [Google Colab](https://colab.research.google.com/)
- [Replit](https://replit.com/)
